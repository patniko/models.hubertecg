{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuBERT-ECG Demo Notebook\n",
    "\n",
    "This notebook demonstrates how to use the HuBERT-ECG model for ECG classification. HuBERT-ECG is a self-supervised foundation model for broad and scalable cardiac applications.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load a pre-trained HuBERT-ECG model from Hugging Face\n",
    "2. Prepare ECG data for inference\n",
    "3. Run inference on the ECG data\n",
    "4. Visualize the results\n",
    "\n",
    "For more information, see the [HuBERT-ECG paper](https://www.medrxiv.org/content/10.1101/2024.11.14.24317328v1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if iterative-stratification is installed\n",
    "try:\n",
    "    import iterative_stratification\n",
    "    print(\"iterative-stratification is installed\")\n",
    "except ImportError:\n",
    "    print(\"Warning: iterative-stratification is not installed. Some functions in utils.py may not work.\")\n",
    "    print(\"You can install it with: pip install iterative-stratification\")\n",
    "\n",
    "# Add the code directory to the path\n",
    "sys.path.append('code')\n",
    "\n",
    "# Import HuBERT-ECG modules\n",
    "from hubert_ecg import HuBERTECG, HuBERTECGConfig\n",
    "from hubert_ecg_classification import HuBERTForECGClassification\n",
    "\n",
    "# Define a simple load_model function to avoid importing from utils\n",
    "def load_model(model_path, device):\n",
    "    \"\"\"Load a pre-trained HuBERT-ECG model from a file.\"\"\"\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model\n",
    "\n",
    "We'll load a pre-trained HuBERT-ECG model from Hugging Face. You can choose between the small, base, or large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model size: 'small', 'base', or 'large'\n",
    "model_size = 'base'\n",
    "\n",
    "# Load pre-trained model from Hugging Face\n",
    "model_name = f\"Edoardo-BS/hubert_ecg_{model_size}\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "try:\n",
    "    # Try to load the model directly from Hugging Face\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    print(\"Model loaded successfully from Hugging Face\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from Hugging Face: {e}\")\n",
    "    print(\"Please download the model manually from https://huggingface.co/Edoardo-BS\")\n",
    "    # If you have downloaded the model locally, you can load it like this:\n",
    "    # model_path = f\"path/to/downloaded/hubert_ecg_{model_size}.pt\"\n",
    "    # model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ECG Data\n",
    "\n",
    "Now, let's prepare some ECG data for inference. We'll use a sample from the PTB-XL dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Setup PTB-XL Dataset\n",
    "\n",
    "Before we can use the PTB-XL dataset, we need to download and process it. You can do this by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "make ptbxl-setup\n",
    "```\n",
    "\n",
    "This will download the PTB-XL dataset from PhysioNet, extract it, and process the ECG data to create .npy files that match the filenames in the CSV files. The processed data will be stored in the `data/ptbxl/processed` directory.\n",
    "\n",
    "Alternatively, you can run the setup script directly:\n",
    "\n",
    "```bash\n",
    "python scripts/setup_ptbxl.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample ECG from the reproducibility folder\n",
    "# Note: You need to download the actual ECG data files using 'make ptbxl-setup'\n",
    "# This is just an example of how to load the data\n",
    "\n",
    "# Load the CSV file with the list of ECGs\n",
    "csv_path = \"reproducibility/ptbxl/ptbxl_all_test.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Loaded {len(df)} ECGs from {csv_path}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample ECG\n",
    "# Make sure you've run 'make ptbxl-setup' to download and process the data\n",
    "sample_filename = df.iloc[0]['filename']\n",
    "ecg_path = os.path.join(\"data/ptbxl/processed\", sample_filename)\n",
    "\n",
    "try:\n",
    "    ecg_data = np.load(ecg_path)\n",
    "    print(f\"Loaded ECG data with shape: {ecg_data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {ecg_path}\")\n",
    "    print(\"Please run 'make ptbxl-setup' to download and process the PTB-XL dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ECG Data\n",
    "\n",
    "Before feeding the ECG data to the model, we need to preprocess it according to the paper's specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ecg(ecg_data, sampling_rate=500, target_length=5000, downsampling_factor=5):\n",
    "    \"\"\"\n",
    "    Preprocess ECG data according to the HuBERT-ECG paper specifications.\n",
    "    \n",
    "    Args:\n",
    "        ecg_data: Raw ECG data with shape (n_leads, n_samples)\n",
    "        sampling_rate: Original sampling rate of the ECG data\n",
    "        target_length: Target length of the ECG data after preprocessing\n",
    "        downsampling_factor: Factor to downsample the ECG data\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed ECG data with shape (1, n_leads, target_length // downsampling_factor)\n",
    "    \"\"\"\n",
    "    # Ensure the ECG data has the right shape\n",
    "    if len(ecg_data.shape) == 1:\n",
    "        ecg_data = ecg_data.reshape(1, -1)  # Single lead\n",
    "    \n",
    "    # Pad or truncate to target length\n",
    "    n_leads, n_samples = ecg_data.shape\n",
    "    if n_samples < target_length:\n",
    "        # Pad with zeros\n",
    "        padded_data = np.zeros((n_leads, target_length))\n",
    "        padded_data[:, :n_samples] = ecg_data\n",
    "        ecg_data = padded_data\n",
    "    elif n_samples > target_length:\n",
    "        # Truncate\n",
    "        ecg_data = ecg_data[:, :target_length]\n",
    "    \n",
    "    # Downsample\n",
    "    if downsampling_factor > 1:\n",
    "        ecg_data = ecg_data[:, ::downsampling_factor]\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    ecg_tensor = torch.tensor(ecg_data, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return ecg_tensor\n",
    "\n",
    "# Preprocess the ECG data if it was loaded successfully\n",
    "try:\n",
    "    preprocessed_ecg = preprocess_ecg(ecg_data)\n",
    "    print(f\"Preprocessed ECG data with shape: {preprocessed_ecg.shape}\")\n",
    "except NameError:\n",
    "    print(\"ECG data not loaded. Please run 'make ptbxl-setup' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference\n",
    "\n",
    "Now, let's run inference on the ECG data using the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, ecg_data):\n",
    "    \"\"\"\n",
    "    Run inference on ECG data using the pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Pre-trained HuBERT-ECG model\n",
    "        ecg_data: Preprocessed ECG data\n",
    "        \n",
    "    Returns:\n",
    "        Model predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(ecg_data.to(device))\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Run inference if the model and preprocessed ECG data are available\n",
    "try:\n",
    "    predictions = run_inference(model, preprocessed_ecg)\n",
    "    print(f\"Model predictions shape: {predictions[0].shape}\")\n",
    "except (NameError, UnboundLocalError):\n",
    "    print(\"Model or preprocessed ECG data not available. Please ensure both are loaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Finally, let's visualize the results of the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ecg_with_predictions(ecg_data, predictions, labels=None):\n",
    "    \"\"\"\n",
    "    Visualize ECG data with model predictions.\n",
    "    \n",
    "    Args:\n",
    "        ecg_data: Raw ECG data\n",
    "        predictions: Model predictions\n",
    "        labels: List of label names\n",
    "    \"\"\"\n",
    "    n_leads, n_samples = ecg_data.shape\n",
    "    \n",
    "    # Plot ECG data\n",
    "    fig, axes = plt.subplots(n_leads, 1, figsize=(15, 3 * n_leads))\n",
    "    if n_leads == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(ecg_data[i])\n",
    "        ax.set_title(f\"Lead {i+1}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Amplitude\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot predictions\n",
    "    if labels is not None and len(predictions) == len(labels):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(labels, predictions)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel(\"Labels\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.title(\"Model Predictions\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Visualize the ECG data if it was loaded successfully\n",
    "try:\n",
    "    visualize_ecg_with_predictions(ecg_data, None)\n",
    "except NameError:\n",
    "    print(\"ECG data not loaded. Please run 'make ptbxl-setup' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example\n",
    "\n",
    "Here's a complete example of loading an ECG, preprocessing it, running inference, and visualizing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete example\n",
    "# Make sure you've run 'make ptbxl-setup' to download and process the data\n",
    "\n",
    "try:\n",
    "    # 1. Load ECG data\n",
    "    sample_filename = df.iloc[0]['filename']\n",
    "    ecg_path = os.path.join(\"data/ptbxl/processed\", sample_filename)\n",
    "    ecg_data = np.load(ecg_path)\n",
    "    print(f\"Loaded ECG data with shape: {ecg_data.shape}\")\n",
    "    \n",
    "    # 2. Preprocess ECG data\n",
    "    preprocessed_ecg = preprocess_ecg(ecg_data)\n",
    "    print(f\"Preprocessed ECG data with shape: {preprocessed_ecg.shape}\")\n",
    "    \n",
    "    # 3. Run inference\n",
    "    predictions = run_inference(model, preprocessed_ecg)\n",
    "    print(f\"Model predictions shape: {predictions[0].shape}\")\n",
    "    \n",
    "    # 4. Visualize results\n",
    "    # Get the column names from the CSV file (excluding the first 4 columns)\n",
    "    label_names = df.columns[4:].tolist()\n",
    "    # Get the predictions for the first sample\n",
    "    pred_values = predictions[0][0].cpu().numpy()\n",
    "    # Ensure the predictions and labels have the same length\n",
    "    if len(pred_values) == len(label_names):\n",
    "        visualize_ecg_with_predictions(ecg_data, pred_values, label_names)\n",
    "    else:\n",
    "        print(f\"Mismatch in prediction length ({len(pred_values)}) and label length ({len(label_names)})\")\n",
    "        visualize_ecg_with_predictions(ecg_data, None)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure you've run 'make ptbxl-setup' to download and process the PTB-XL dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the HuBERT-ECG model for ECG classification. We covered loading a pre-trained model, preprocessing ECG data, running inference, and visualizing the results.\n",
    "\n",
    "For more information, see the [HuBERT-ECG paper](https://www.medrxiv.org/content/10.1101/2024.11.14.24317328v1) and the [HuBERT-ECG GitHub repository](https://github.com/your-username/HuBERT-ECG)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
